<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Simulations | Biostatistician</title>
    <link>https://gasparyan.co/tag/simulations/</link>
      <atom:link href="https://gasparyan.co/tag/simulations/index.xml" rel="self" type="application/rss+xml" />
    <description>Simulations</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>Â© 2022 Samvel B. Gasparyan</copyright><lastBuildDate>Thu, 30 Dec 2021 10:00:00 +0400</lastBuildDate>
    <image>
      <url>https://gasparyan.co/images/icon_hu37ae94fde7f6135a8e8cfd653ea9ade8_11929814_512x512_fill_lanczos_center_2.png</url>
      <title>Simulations</title>
      <link>https://gasparyan.co/tag/simulations/</link>
    </image>
    
    <item>
      <title>Neyman-Pearson and some other Uniformly Most Powerful Tests</title>
      <link>https://gasparyan.co/post/neymanpearson/2021-12-30-r-rmarkdown/</link>
      <pubDate>Thu, 30 Dec 2021 10:00:00 +0400</pubDate>
      <guid>https://gasparyan.co/post/neymanpearson/2021-12-30-r-rmarkdown/</guid>
      <description>
&lt;script src=&#34;https://gasparyan.co/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;introduction&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Introduction&lt;/h3&gt;
&lt;p&gt;Suppose data consisting of i.i.d. observations &lt;span class=&#34;math inline&#34;&gt;\(X^n=(X_1,X_2,\cdots,X_n)\)&lt;/span&gt; are available from a distribution &lt;span class=&#34;math inline&#34;&gt;\(F(x,\theta),\,\theta\in\Theta\subset\mathbf{R}.\)&lt;/span&gt; The exact value &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; corresponding to the distribution that generated the observations is unknown. The problem is, using the available data &lt;span class=&#34;math inline&#34;&gt;\(X^n,\)&lt;/span&gt; construct tests for making decisions on the possible value of unknown parameter &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt;. Unlike the estimation problems where an estimator is constructed based on data which can be used as an approximate value of the unknown parameter &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt;, the hypothesis testing deals with decisions, for example, whether the unknown parameter is in a given subset (the null hypothesis)
&lt;span class=&#34;math display&#34;&gt;\[{\mathcal H}_0:\ \ \theta\in\Theta_0\subset\Theta,\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;or, alternatively, in its supplement
&lt;span class=&#34;math display&#34;&gt;\[{\mathcal H}_a:\ \ \theta\in\Theta\setminus\Theta_0.\]&lt;/span&gt;
Therefore, hypothesis testing is interested in knowing whether the unknown value is in a given set &lt;span class=&#34;math inline&#34;&gt;\(\Theta_0\)&lt;/span&gt;. We may define this set as containing only one value &lt;span class=&#34;math inline&#34;&gt;\(\Theta_0=\{\theta_0\}\)&lt;/span&gt; in which case the test will be whether the unknown value is equal to the given known value &lt;span class=&#34;math inline&#34;&gt;\(\theta_0\)&lt;/span&gt;. The statistical tests that make the decisions are based on the data and the construction of statistical tests can be formalized as follows.&lt;/p&gt;
&lt;p&gt;Suppose &lt;span class=&#34;math inline&#34;&gt;\(\psi:\mathbf{R^n}\rightarrow\{0,1\}\)&lt;/span&gt; is a measurable function defined for all observations &lt;span class=&#34;math inline&#34;&gt;\(X^n\)&lt;/span&gt; and takes only the values 0 and 1. Any such function will be called a &lt;em&gt;statistical test.&lt;/em&gt; We will use the convention that the value 1 corresponds to the decision of rejecting the null hypothesis (hence the alternative hypothesis should be accepted), while the value 0 means a decision that the null hypothesis should be accepted. Hence using the available observations &lt;span class=&#34;math inline&#34;&gt;\(X^n\)&lt;/span&gt; we can make a decision based on the value of &lt;span class=&#34;math inline&#34;&gt;\(\psi(X^n).\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;As we have seen from the definition of a statistical test, any measurable function is a test, including the functions that are constant &lt;span class=&#34;math inline&#34;&gt;\(\psi\equiv1\)&lt;/span&gt; (data independent tests), which are not good tests at all since those will always give the same answer regardless of the data, and hence, will very likely be wrong in most cases. Therefore, we need to define tests that have good properties (give reliable answers), and before this we need to define what a good test should be in a formal way. We will be dealing only with small sample statistical tests, meaning the sample size &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; is fixed and the properties of statistical test will be considered under this condition only (unlike the asymptotic theory, where a large sample inference is done under the condition when &lt;span class=&#34;math inline&#34;&gt;\(n\rightarrow+\infty\)&lt;/span&gt;).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;type-i-and-ii-errors&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Type I and II errors&lt;/h3&gt;
&lt;p&gt;For each statistical test &lt;span class=&#34;math inline&#34;&gt;\(\psi\)&lt;/span&gt; we may either make a correct decision (correctly identify the set to which the unknown value &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; belongs) or commit one of two errors: reject the null hypothesis when it is true (type I error) or accept when it is false (type II error). If the sample size &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; is fixed, it is impossible to construct a test with both types of errors being low, hence the strategy is to fix some level for the type I error (&lt;em&gt;level of significance&lt;/em&gt;) and among those tests find a test with the lowest type II error.&lt;/p&gt;
&lt;p&gt;Indeed, consider the type I error of a given statistical test &lt;span class=&#34;math inline&#34;&gt;\(\psi.\)&lt;/span&gt; The type I error, denoting it by &lt;span class=&#34;math inline&#34;&gt;\(\alpha(\psi),\)&lt;/span&gt; will be
&lt;span class=&#34;math display&#34;&gt;\[\alpha(\psi,\theta) = P_\theta(\psi=1)=E_\theta\psi,\ \ \theta\in\Theta_0.\]&lt;/span&gt;
That is, the probability of rejecting that &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; is in &lt;span class=&#34;math inline&#34;&gt;\(\Theta_0\)&lt;/span&gt; (the decision is &lt;span class=&#34;math inline&#34;&gt;\(\psi=1\)&lt;/span&gt;) while &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; is indeed in &lt;span class=&#34;math inline&#34;&gt;\(\Theta_0.\)&lt;/span&gt; For a given &lt;em&gt;significance level&lt;/em&gt; &lt;span class=&#34;math inline&#34;&gt;\(\alpha\in(0,1)\)&lt;/span&gt;, we consider only tests &lt;span class=&#34;math inline&#34;&gt;\(\psi\)&lt;/span&gt; such that
&lt;span class=&#34;math display&#34;&gt;\[\alpha(\psi,\theta)\leq\alpha,\ \ \theta\in\Theta_0.\]&lt;/span&gt;
Among these tests we will try to find the one with the lowest type II error. Or, equivalently, if we denote by &lt;span class=&#34;math inline&#34;&gt;\(\pi(\psi,\theta)=P_\theta(\psi=1)=E_\theta\psi,\ \ \theta\in\Theta\setminus\Theta_0,\)&lt;/span&gt; the &lt;em&gt;power function&lt;/em&gt; of the test &lt;span class=&#34;math inline&#34;&gt;\(\psi,\)&lt;/span&gt; then the problem above can be formulated as finding a test with the highest power in the region &lt;span class=&#34;math inline&#34;&gt;\(\Theta\setminus\Theta_0\)&lt;/span&gt; among the tests with the given significance level &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; in the region &lt;span class=&#34;math inline&#34;&gt;\(\Theta_0.\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The hypothesis testing will be called &lt;em&gt;simple&lt;/em&gt; if both &lt;span class=&#34;math inline&#34;&gt;\(\Theta_0\)&lt;/span&gt; and its complement consist of only single values.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;neyman-pearson-test&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Neyman-Pearson test&lt;/h3&gt;
&lt;p&gt;Consider the case of simple hypothesis testing. We observe from a random variable &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; which has a distribution function &lt;span class=&#34;math inline&#34;&gt;\(F(x),\)&lt;/span&gt; &lt;span class=&#34;math inline&#34;&gt;\(X\sim F(x)\)&lt;/span&gt;. The simple hypothesis to be tested is the following:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[{\mathcal H}_0:\ \ F(x)=F_0(x),\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;and the alternative hypothesis is
&lt;span class=&#34;math display&#34;&gt;\[{\mathcal H}_a:\ \ F(x)=F_1(x).\]&lt;/span&gt;
Here &lt;span class=&#34;math inline&#34;&gt;\(F_0(x)\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(F_1(x)\)&lt;/span&gt; are given distribution functions.&lt;/p&gt;
&lt;p&gt;Suppose the distribution function &lt;span class=&#34;math inline&#34;&gt;\(F_0(x)\)&lt;/span&gt; has a density &lt;span class=&#34;math inline&#34;&gt;\(f_0(x)\)&lt;/span&gt; with respect to some measure &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;, while &lt;span class=&#34;math inline&#34;&gt;\(F_1(x)\)&lt;/span&gt; has a density &lt;span class=&#34;math inline&#34;&gt;\(f_1(x),\)&lt;/span&gt; with respect to the same measure. Such a measure always exists since we can take the measure generated by the distribution function &lt;span class=&#34;math inline&#34;&gt;\(\tilde F(x)=\frac{F_0(x)+F_1(x)}{2}\)&lt;/span&gt;. The &lt;strong&gt;Neyman-Pearson&lt;/strong&gt; fundamental lemma &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-lehmann2005testing&#34; role=&#34;doc-biblioref&#34;&gt;Lehmann and Romano 2005&lt;/a&gt;)&lt;/span&gt; says that:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;For a given significance level &lt;span class=&#34;math inline&#34;&gt;\(\alpha\in(0,1)\)&lt;/span&gt; there exists a value &lt;span class=&#34;math inline&#34;&gt;\(c_0\in\mathbf{R}\)&lt;/span&gt; such that the following &lt;em&gt;Neyman-Pearson (NP)&lt;/em&gt; test
&lt;span class=&#34;math display&#34;&gt;\[\tilde\psi_{c_0}(x)=\left\{
\begin{matrix}
1, &amp;amp; x\in\{x:\,f_1(x)&amp;gt;c_0f_0(x)\},\\
\frac{\alpha-\alpha(c_0)}{\alpha(c_0-0)-\alpha(c_0)}, &amp;amp; x\in\{x:\,f_1(x)=c_0f_0(x)\},\\
0, &amp;amp; x\in\{x:\,f_1(x)&amp;lt;c_0f_0(x)\},
\end{matrix}\right.
\]&lt;/span&gt;
satisfies the equality &lt;span class=&#34;math inline&#34;&gt;\(E_{\theta_0}\tilde\psi_{c_0}(X)=\alpha.\)&lt;/span&gt; Here
&lt;span class=&#34;math display&#34;&gt;\[\alpha(c)=P_0(f_1(X)&amp;gt;cf_0(X)),\]&lt;/span&gt;
and &lt;span class=&#34;math inline&#34;&gt;\(c_0\)&lt;/span&gt; is such that &lt;span class=&#34;math inline&#34;&gt;\(\alpha(c_0)\leq \alpha\leq\alpha(c_0-0).\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The test &lt;span class=&#34;math inline&#34;&gt;\(\tilde\psi_c\)&lt;/span&gt; is most powerful at the significance level &lt;span class=&#34;math inline&#34;&gt;\(\alpha.\)&lt;/span&gt; Meaning that for any test &lt;span class=&#34;math inline&#34;&gt;\(\psi\)&lt;/span&gt; which is of &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; level, that is, &lt;span class=&#34;math inline&#34;&gt;\(E_{0}(X)\psi\leq \alpha,\)&lt;/span&gt; the power of that test does not exceed the power of the test &lt;span class=&#34;math inline&#34;&gt;\(\tilde\psi_{c_0}\)&lt;/span&gt;, &lt;span class=&#34;math display&#34;&gt;\[E_{1}\tilde\psi_{c_0}(X)-E_{1}\psi(X)\geq \int\left[\tilde\psi_{c_0}(x)-\psi(x)\right]f_1(x)d \mu\geq 0.\]&lt;/span&gt;
Indeed, if &lt;span class=&#34;math inline&#34;&gt;\(\tilde \psi_{c_0}(x)&amp;gt;\psi(x)\geq 0,\)&lt;/span&gt; then necessarily &lt;span class=&#34;math inline&#34;&gt;\(\tilde \psi_{c_0}(x)\neq 0\)&lt;/span&gt; hence &lt;span class=&#34;math inline&#34;&gt;\(f_1(x)\geq c_0f_0(x).\)&lt;/span&gt; While, in the same way, if &lt;span class=&#34;math inline&#34;&gt;\(\tilde \psi_{c_0}(x)&amp;lt;\psi(x)\geq 1,\)&lt;/span&gt; then necessarily &lt;span class=&#34;math inline&#34;&gt;\(\tilde \psi_{c_0}(x)\neq 1\)&lt;/span&gt; hence &lt;span class=&#34;math inline&#34;&gt;\(f_1(x)\leq c_0f_0(x).\)&lt;/span&gt; Therefore,
&lt;span class=&#34;math display&#34;&gt;\[\int\left(\tilde\psi_{c_0}(x)-\psi(x)\right)(f_1(x)-c_0f_0(x))d\mu\geq 0.\]&lt;/span&gt;
Which entails that
&lt;span class=&#34;math display&#34;&gt;\[\int\left(\tilde\psi_{c_0}(x)-\psi(x)\right)f_1(x)d\mu\geq c_0\int\left(\tilde\psi_{c_0}(x)-\psi(x)\right)f_0(x)d\mu=c_0[a-E_0\psi(X)]\geq 0.\]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;If a test &lt;span class=&#34;math inline&#34;&gt;\(\psi\)&lt;/span&gt; is most powerful at level &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; for testing &lt;span class=&#34;math inline&#34;&gt;\(f_0(x)\)&lt;/span&gt; against &lt;span class=&#34;math inline&#34;&gt;\(f_1(x)\)&lt;/span&gt;, then for some &lt;span class=&#34;math inline&#34;&gt;\(c\)&lt;/span&gt; it can be written as &lt;span class=&#34;math inline&#34;&gt;\(\psi=\tilde\psi_c,\)&lt;/span&gt; almost everywhere on the set &lt;span class=&#34;math inline&#34;&gt;\(\{f_1(x)\neq c_0 f_0(x)\}\)&lt;/span&gt;. Furthermore, for the most powerful test &lt;span class=&#34;math inline&#34;&gt;\(\psi\)&lt;/span&gt; the equality &lt;span class=&#34;math inline&#34;&gt;\(E_{\theta_0}\psi(X)=\alpha\)&lt;/span&gt; will be satisfied unless there exists a test of size &lt;span class=&#34;math inline&#34;&gt;\(&amp;lt;\alpha\)&lt;/span&gt; and with power 1.
Since the &lt;em&gt;NP&lt;/em&gt; test always exists and is most powerful, this third point essentially means the uniqueness (almost everywhere) of most powerful tests, except possibly on the set &lt;span class=&#34;math inline&#34;&gt;\(\{f_1(x)= c_0 f_0(x)\}\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Remark.&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;For a given &lt;span class=&#34;math inline&#34;&gt;\(\alpha\in(0,1)\)&lt;/span&gt; the value &lt;span class=&#34;math inline&#34;&gt;\(c_0\)&lt;/span&gt; always exits since &lt;span class=&#34;math inline&#34;&gt;\(1-\alpha(c)\)&lt;/span&gt; is a distribution function.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The constructed test is &lt;em&gt;randomized&lt;/em&gt;, meaning that it does not take only the values &lt;span class=&#34;math inline&#34;&gt;\({0,1},\)&lt;/span&gt; but can take also a value between 0 and 1, which can be interpreted as the probability of rejecting the null hypothesis. Hence, as a result of this statistical test, the decision to reject or accept the null hypothesis sometimes may not be made, but a probability is assigned to rejecting the null hypothesis.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;If the set &lt;span class=&#34;math inline&#34;&gt;\(\{x:\,f_1(x)=c_0f_0(x)\}\)&lt;/span&gt; has the &lt;span class=&#34;math inline&#34;&gt;\(\mu-\)&lt;/span&gt;measure zero, then the most powerful test is determined uniquely (up to sets of measure zero) by the &lt;em&gt;Neyman-Pearson&lt;/em&gt; lemma. This will happen if, for example, both &lt;span class=&#34;math inline&#34;&gt;\(f_1(x)\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(f_0(x)\)&lt;/span&gt; are continuous and &lt;span class=&#34;math inline&#34;&gt;\(f_0(x)&amp;gt;0,\)&lt;/span&gt; almost everywhere.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;In practice randomization is not considered acceptable and hence an &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; value is selected so that a &lt;em&gt;non-randomized&lt;/em&gt; test exists.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Example.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Consider a single observation &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; from a &lt;em&gt;Poisson distribution&lt;/em&gt;, that is&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[f(k,\theta)=P(X=k)=\frac{\theta^k}{k!}e^{-\theta},\ \ k=0,1,2,\cdots.\]&lt;/span&gt;
We are testing the simple hypothesis&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[{\mathcal H}_0:\ \ \theta=\theta_0,\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;against the alternative hypothesis
&lt;span class=&#34;math display&#34;&gt;\[{\mathcal H}_a:\ \ \theta=\theta_1&amp;gt;\theta_0.\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;In this case
&lt;span class=&#34;math display&#34;&gt;\[\frac{f(X,\theta_1)}{f(X,\theta_0)}=\left(\frac{\theta_1}{\theta_0}\right)^Xe^{-(\theta_1-\theta_0)}&amp;gt;\tilde c\]&lt;/span&gt;
is equivalent to &lt;span class=&#34;math inline&#34;&gt;\(X&amp;gt;c,\)&lt;/span&gt; because of the fact that &lt;span class=&#34;math inline&#34;&gt;\(\theta_1&amp;gt;\theta_0.\)&lt;/span&gt; Hence the most powerful test will be&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\tilde\psi_{c_0}(X)=\left\{
\begin{matrix}
&amp;amp;1, &amp;amp; X&amp;gt;c_0,\\
&amp;amp;\frac{F(c_0,\theta_0)-(1-\alpha)}{F(c_0,\theta_0)-F(c_0-0,\theta_0)}, &amp;amp; X=c_0,\\
&amp;amp;0, &amp;amp; X&amp;lt;c_0.
\end{matrix}\right.
\]&lt;/span&gt;
Here &lt;span class=&#34;math inline&#34;&gt;\(c_0\)&lt;/span&gt; is such that &lt;span class=&#34;math inline&#34;&gt;\(F(c_0-0,\theta_0)\leq 1-\alpha\leq F(c_0,\theta_0).\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;As noted above, to avoid randomized tests we can select the significance level in a way so that the set &lt;span class=&#34;math inline&#34;&gt;\(\{X=c_0\}\)&lt;/span&gt; has the measure zero. This can be achieved by replacing the given significance level &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; by a more conservative (lower) significance level &lt;span class=&#34;math inline&#34;&gt;\(\alpha_0\)&lt;/span&gt; so that &lt;span class=&#34;math inline&#34;&gt;\(1-\alpha_0=F(c_0,\theta_0).\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Take the case of &lt;span class=&#34;math inline&#34;&gt;\(\theta_0=1,\,\theta_1=2,\,\alpha=0.05.\)&lt;/span&gt; In this case,&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[F(3-0, 1)\leq 1-\alpha\leq F(3,1),\]&lt;/span&gt;
therefore, &lt;span class=&#34;math inline&#34;&gt;\(c_0=3.\)&lt;/span&gt; This value can be found as follows&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;alpha &amp;lt;- 0.05
theta0 &amp;lt;- 1
theta1 &amp;lt;- 2
Y &amp;lt;- ppois(1:100, theta0)
Z &amp;lt;- which(Y &amp;gt; 1- alpha, Y)
c0 &amp;lt;- Z[1]
c0&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 3&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If we test at the given significance level &lt;span class=&#34;math inline&#34;&gt;\(\alpha=0.05,\)&lt;/span&gt; then the Neyman-Pearson test will be randomized and on the set &lt;span class=&#34;math inline&#34;&gt;\(\{X=3\}\)&lt;/span&gt; it will have the following value&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;(ppois(c0,theta0)-(1-alpha))/(ppois(c0,theta0)-ppois(c0-1,theta0))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.5057936&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Hence, on this set the probability of rejecting the null hypothesis is around 0.5, hence no decision can be made. On the other hand, if we take a more conservative significance level &lt;span class=&#34;math inline&#34;&gt;\(\alpha_0\)&lt;/span&gt; as follows&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;alpha0 &amp;lt;- 1-ppois(c0,theta0)
alpha0&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.01898816&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this case we can get a non-randomized test with the power equal to&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ppois(c0,theta1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.8571235&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level3 unnumbered&#34;&gt;
&lt;h3&gt;References&lt;/h3&gt;
&lt;div id=&#34;refs&#34; class=&#34;references csl-bib-body hanging-indent&#34;&gt;
&lt;div id=&#34;ref-lehmann2005testing&#34; class=&#34;csl-entry&#34;&gt;
Lehmann, Erich Leo, and Joseph P Romano. 2005. &lt;em&gt;Testing Statistical Hypotheses&lt;/em&gt;. 3rd ed. Vol. 3. Springer.
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Win Odds Confidence Intervals in R</title>
      <link>https://gasparyan.co/post/wrci/2020-01-10-r-rmarkdown/</link>
      <pubDate>Fri, 10 Jan 2020 10:00:00 +0400</pubDate>
      <guid>https://gasparyan.co/post/wrci/2020-01-10-r-rmarkdown/</guid>
      <description>
&lt;script src=&#34;https://gasparyan.co/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;mann-whitney-estimate-for-the-win-probability&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Mann-Whitney estimate for the win probability&lt;/h2&gt;
&lt;p&gt;Consider two independent, continuous RVs (random variables) &lt;span class=&#34;math inline&#34;&gt;\(\xi\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\eta\)&lt;/span&gt;. The following probability is called the &lt;em&gt;win probability&lt;/em&gt; of RV &lt;span class=&#34;math inline&#34;&gt;\(\eta\)&lt;/span&gt; against the RV &lt;span class=&#34;math inline&#34;&gt;\(\xi\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{align*}
\theta=P(\eta&amp;gt;\xi).
\end{align*}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Given an i.i.d. (independent, identically distributed) random sample from &lt;span class=&#34;math inline&#34;&gt;\(\xi,\)&lt;/span&gt; denoted by &lt;span class=&#34;math inline&#34;&gt;\(X=(X_1,\cdots,X_{n_1})\)&lt;/span&gt; and an i.i.d. sample from &lt;span class=&#34;math inline&#34;&gt;\(\eta\)&lt;/span&gt; denoted by &lt;span class=&#34;math inline&#34;&gt;\(Y=(Y_1,\cdots,Y_{n_2})\)&lt;/span&gt; we are interested in estimating the unknown parameter &lt;span class=&#34;math inline&#34;&gt;\(\theta.\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The following estimator is called the &lt;em&gt;Mann-Whitney&lt;/em&gt; estimator (or, the &lt;em&gt;win proportion&lt;/em&gt;) for the win probability&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{align*}
\hat\theta_N=\frac{1}{n_1n_2}\sum_{i=1}^{n_1}\sum_{j=1}^{n_2}I(X_i&amp;lt;Y_j).
\end{align*}\]&lt;/span&gt;
Here &lt;span class=&#34;math inline&#34;&gt;\(N=n_1+n_2\)&lt;/span&gt; is the total sample size, whereas &lt;span class=&#34;math inline&#34;&gt;\(I(\cdot)\)&lt;/span&gt; is the indicator function which takes the value 1 if the underlying inequality is true and 0 otherwise. When &lt;span class=&#34;math inline&#34;&gt;\(n_1\rightarrow+\infty,\,n_2\rightarrow+\infty\)&lt;/span&gt; then the win proportion is a consistent estimator (convergence in probability) for the win probability
&lt;span class=&#34;math display&#34;&gt;\[\begin{align*}
\hat\theta_N\longrightarrow\theta.
\end{align*}\]&lt;/span&gt;
If &lt;span class=&#34;math inline&#34;&gt;\(\frac{n_1}{N}\rightarrow \alpha,\)&lt;/span&gt; as &lt;span class=&#34;math inline&#34;&gt;\(n_1\rightarrow+\infty,\,n_2\rightarrow+\infty,\)&lt;/span&gt; then the win proportion is also asymptotically normal
&lt;span class=&#34;math display&#34;&gt;\[\begin{align*}
\sqrt{N}(\hat\theta_N-\theta)\Longrightarrow{\mathcal N}\left(0,\frac{1}{1-\alpha}\sigma_{10}^2+\frac{1}{\alpha}\sigma_{01}^2\right).
\end{align*}\]&lt;/span&gt;
Here,
&lt;span class=&#34;math display&#34;&gt;\[\begin{align*}
\sigma_{10}^2=Cov(I(\xi&amp;lt;\eta),I(\xi&amp;#39;&amp;lt;\eta))=P(\xi&amp;lt;\eta,\xi&amp;#39;&amp;lt;\eta)-P(\xi&amp;lt;\eta)^2,\\
\sigma_{01}^2=Cov(I(\xi&amp;lt;\eta),I(\xi&amp;lt;\eta&amp;#39;))=P(\xi&amp;lt;\eta,\xi&amp;lt;\eta&amp;#39;)-P(\xi&amp;lt;\eta)^2,
\end{align*}\]&lt;/span&gt;
where &lt;span class=&#34;math inline&#34;&gt;\(\xi&amp;#39;\)&lt;/span&gt; has the same distribution as &lt;span class=&#34;math inline&#34;&gt;\(\xi\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\eta&amp;#39;\)&lt;/span&gt; has the same distribution as &lt;span class=&#34;math inline&#34;&gt;\(\eta\)&lt;/span&gt;. All &lt;span class=&#34;math inline&#34;&gt;\(\xi,\xi&amp;#39;,\eta,\eta&amp;#39;\)&lt;/span&gt; are independent.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;application-to-exponential-distributions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Application to exponential distributions&lt;/h2&gt;
&lt;p&gt;Suppose now that &lt;span class=&#34;math inline&#34;&gt;\(\xi\sim{\mathbb E}(\lambda)\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\eta\sim{\mathbb E}(\mu).\)&lt;/span&gt; In this case,&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{align*}
\sigma_{10}^2=\frac{2\lambda}{(\lambda+\mu)(2\lambda+\mu)}-\frac{\lambda^2}{(\lambda+\mu)^2}=\frac{\lambda^2\mu}{(\lambda+\mu)^2(2\lambda+\mu)}\\
\sigma_{01}^2=\frac{\lambda}{\lambda+2\mu}-\frac{\lambda^2}{(\lambda+\mu)^2}=\frac{\lambda\mu^2}{(\lambda+\mu)^2(\lambda+2\mu)},
\end{align*}\]&lt;/span&gt;
therefore, the asymptotic variance of the win proportion will be
&lt;span class=&#34;math display&#34;&gt;\[\begin{align*}
\sigma^2=\frac{\lambda\mu}{(\lambda+\mu)^2}\left(\frac{1}{1-\alpha}\frac{\lambda}{2\lambda+\mu}+\frac{1}{\alpha}\frac{\mu}{\lambda+2\mu}\right).
\end{align*}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;We can check this by the following simulations&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;n1 &amp;lt;- 700
n2 &amp;lt;- 100
N &amp;lt;- n1 + n2
m &amp;lt;- 1000
lambda &amp;lt;- 2
mu &amp;lt;- 10
alpha &amp;lt;- n1/(n1+n2)


k &amp;lt;- lambda/(lambda+mu)
WR &amp;lt;-NULL

for(i in 1:m){
  set.seed(i)
  X1 &amp;lt;- rexp(n1,lambda)
  X2 &amp;lt;- rexp(n2,mu)
  d &amp;lt;- expand.grid(x=X1,y=X2)
  d$w &amp;lt;- ifelse(d$y&amp;gt;d$x,1,ifelse(d$y==d$x,0.5,0))
  WR[i]&amp;lt;-sqrt(N)*(mean(d$w)-k)
}


x0&amp;lt;-3
int &amp;lt;- seq(-x0,x0,0.001)

Coeff0 &amp;lt;- mu*lambda/(lambda+mu)^2
Coeff &amp;lt;- Coeff0*(1/(1-alpha)*lambda/(2*lambda+mu)+1/alpha*mu/(lambda+2*mu))


hist(WR, nclass = 20, freq=FALSE, xlim=c(-x0,x0), 
     ylim=c(0, 1.1), col = &amp;quot;lightblue&amp;quot;, border = &amp;quot;blue&amp;quot;)
lines(int,dnorm(int, mean = 0, sd=sqrt(Coeff)), col=&amp;quot;2&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://gasparyan.co/post/wrci/2020-01-10-r-rmarkdown_files/figure-html/unnamed-chunk-1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;definition-of-the-win-odds&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Definition of the win odds&lt;/h2&gt;
&lt;p&gt;Consider two independent, continuous RVs (random variables) &lt;span class=&#34;math inline&#34;&gt;\(\xi\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\eta\)&lt;/span&gt;. The odds of the win probability is called the &lt;em&gt;win odds&lt;/em&gt; of RV &lt;span class=&#34;math inline&#34;&gt;\(\eta\)&lt;/span&gt; against the RV &lt;span class=&#34;math inline&#34;&gt;\(\xi\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{align*}
\omega=\frac{P(\eta&amp;gt;\xi)}{P(\eta&amp;lt;\xi)}=\frac{\theta}{1-\theta}.
\end{align*}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The Mann-Whitney estimate of the win probability can be transformed by the function &lt;span class=&#34;math inline&#34;&gt;\(f(x)=\frac{x}{1-x},\ \ x\in(0,1)\)&lt;/span&gt; to get an estimate for the win odds. Using the same transformation and the asymptotic normality of the Mann-Whitney estimate it is possible to construct asymptotic confidence intervals for the win odds, for a given asymptotic confidence level.&lt;/p&gt;
&lt;p&gt;If &lt;span class=&#34;math inline&#34;&gt;\(\omega=1\)&lt;/span&gt; then the random variables &lt;span class=&#34;math inline&#34;&gt;\(\xi\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\eta\)&lt;/span&gt; are stochastically equivalent, while &lt;span class=&#34;math inline&#34;&gt;\(\omega&amp;gt;1\)&lt;/span&gt; means that &lt;span class=&#34;math inline&#34;&gt;\(\eta\)&lt;/span&gt; is stochastically greater than (wins against) &lt;span class=&#34;math inline&#34;&gt;\(\eta.\)&lt;/span&gt; The case &lt;span class=&#34;math inline&#34;&gt;\(\omega&amp;lt;1\)&lt;/span&gt; means that &lt;span class=&#34;math inline&#34;&gt;\(\eta\)&lt;/span&gt; loses against &lt;span class=&#34;math inline&#34;&gt;\(\xi\)&lt;/span&gt;. The asymptotic confidence interval of the win odds can be used to test the hypothesis whether &lt;span class=&#34;math inline&#34;&gt;\(\omega=1\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;To use the asymptotic normality result described above we need to estimate the asymptotic variance. The package &lt;em&gt;sanon&lt;/em&gt; in &lt;em&gt;R&lt;/em&gt; allows to estimate the asymptotic standard error of the Mann-Whitney estimate.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;the-package-sanon&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The package sanon&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#install.packages(&amp;quot;sanon&amp;quot;)
library(sanon)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The dataset &lt;em&gt;resp&lt;/em&gt; contains data from a randomized clinical trial to compare a test treatment to placebo for a respiratory disorder.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data(resp, package = &amp;quot;sanon&amp;quot;)

head(resp)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   center treatment sex age baseline visit1 visit2 visit3 visit4
## 1      1         A   F  32        1      2      2      4      2
## 2      2         A   F  37        1      3      4      4      4
## 3      1         A   F  47        2      2      3      4      4
## 4      2         A   F  39        2      3      4      4      4
## 5      1         A   M  11        4      4      4      4      2
## 6      2         A   F  60        4      4      3      3      4&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The column &lt;em&gt;visit4&lt;/em&gt; is a numeric vector for patient global ratings of symptom control according to 5 categories (4 = excellent, 3 = good, 2 = fair, 1 = poor, 0 = terrible), measured at visit 4. To compare the effect of active treatment against the placebo we will use the win probability, which, as we defined previously, is an unknown theoretical quantity. The null hypothesis is that there is no treatment difference which can be written in terms of the win probability as &lt;span class=&#34;math inline&#34;&gt;\(\theta=0.5.\)&lt;/span&gt; The Mann-Whitney estimate of the win probability can be calculated as follows&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fit &amp;lt;- sanon(visit4 ~ grp(treatment, ref=&amp;quot;P&amp;quot;), data = resp)

fit&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Call:
## sanon.formula(formula = visit4 ~ grp(treatment, ref = &amp;quot;P&amp;quot;), data = resp)
## 
## Sample size: 111
## 
## Response levels:
## [visit4; 5 levels] (lower) 0, 1, 2, 3, 4 (higher)
## 
## Design Matrix:
##        [,1]
## visit4    1
## 
## Mann-Whitney Estimate 
##  for comparison [ A / P ] :
## visit4 
## 0.6174&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;confint(fit)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## M-W Estimate and 95% Confidence Intervals 
## :
##        Estimate  Lower  Upper
## visit4   0.6174 0.5173 0.7176&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fit$p&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##            [,1]
## [1,] 0.02150601&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The p-value based on the asymptotic confidence interval of level 0.05 is less than 0.05, hence the null hypothesis of no treatment difference is rejected. The Mann-Whitney estimate can be transformed to get an estimate for the win odds.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;confint(fit)$ci/(1-confint(fit)$ci)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        Estimate    Lower    Upper
## visit4 1.614013 1.071762 2.540746&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For the win odds the null hypothesis of no treatment difference is &lt;span class=&#34;math inline&#34;&gt;\(\omega=1.\)&lt;/span&gt; The win odds 1.61 characterizes the treatment effect difference.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Exponential Distribution</title>
      <link>https://gasparyan.co/post/exp/2019-12-20-r-rmarkdown/</link>
      <pubDate>Fri, 20 Dec 2019 10:00:00 +0400</pubDate>
      <guid>https://gasparyan.co/post/exp/2019-12-20-r-rmarkdown/</guid>
      <description>
&lt;script src=&#34;https://gasparyan.co/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;introduction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;This is a short reminder of some simple properties of exponential distributions.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;The continuous random variable (RV) &lt;span class=&#34;math inline&#34;&gt;\(\xi\)&lt;/span&gt; has an exponential distribution with the rate &lt;span class=&#34;math inline&#34;&gt;\(\lambda&amp;gt;0\)&lt;/span&gt; if its CMD (cumulative distribution function) has the following form&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[F_\xi(x)=P(\xi&amp;lt;x)=\left\{\begin{matrix}
&amp;amp;1-e^{-\lambda x}, &amp;amp;x\geq 0.\\
&amp;amp;0 &amp;amp;x&amp;lt;0.
\end{matrix}\right.
\]&lt;/span&gt;
This entails that an exponential RV is with 1 probability positive and has the PDF (probability density function)
&lt;span class=&#34;math display&#34;&gt;\[f_\xi(x)=F_\xi&amp;#39;(x)=\left\{\begin{matrix}
&amp;amp;\lambda e^{-\lambda x}, &amp;amp;x&amp;gt;0,\\
&amp;amp;0 &amp;amp;x&amp;lt;0.
\end{matrix}\right.
\]&lt;/span&gt;
If &lt;span class=&#34;math inline&#34;&gt;\(\xi\)&lt;/span&gt; has an exponential distribution with the rate &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt; we will denote this by &lt;span class=&#34;math inline&#34;&gt;\({\mathbb E}(\lambda).\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;In &lt;span class=&#34;math inline&#34;&gt;\(R\)&lt;/span&gt; the following functions can be used to, correspondingly, generate numbers from &lt;span class=&#34;math inline&#34;&gt;\({\mathbb E}(\lambda)\)&lt;/span&gt;, calculate values of CDF, calculate values of PDF&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rexp(n=2, rate=1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.06697548 0.25507292&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pexp(q=1, rate=1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.6321206&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dexp(x=1, rate=1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.3678794&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;em&gt;histogram&lt;/em&gt; is a non-parametric estimator for the PDF. Hence we can simulate data from an exponential distribution and show that the histogram based on the data fits the PDF. Consider the case of &lt;span class=&#34;math inline&#34;&gt;\({\mathbb E}(2)\)&lt;/span&gt; and simulate a sample of size &lt;span class=&#34;math inline&#34;&gt;\(n=10000.\)&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rm(list=ls())

n &amp;lt;- 10000
lambda &amp;lt;- 2

X &amp;lt;- rexp(n = n, rate = lambda)
int &amp;lt;- seq(0, max(X), max(X)/100)

hist(X, freq = FALSE, nclass = 50, col = &amp;quot;lightblue&amp;quot;, 
     border = &amp;quot;blue&amp;quot;, ylim = c(0, 2), main = &amp;quot;&amp;quot;)
lines(int, dexp(int, rate = lambda), col = &amp;quot;red&amp;quot;, lty = 2, lwd = 2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://gasparyan.co/post/exp/2019-12-20-r-rmarkdown_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This is a very useful technique to check whether the RVs have the given PDF. We will use this technique below.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;example-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Example 1&lt;/h2&gt;
&lt;p&gt;Suppose &lt;span class=&#34;math inline&#34;&gt;\(\xi\sim {\mathbb E}(\lambda)\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\eta\sim {\mathbb E}(\mu)\)&lt;/span&gt; are independent. Calculate the PDF of the RV &lt;span class=&#34;math inline&#34;&gt;\(\zeta=\eta-\xi.\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;First consider the case of &lt;span class=&#34;math inline&#34;&gt;\(z&amp;gt;0.\)&lt;/span&gt; Since &lt;span class=&#34;math inline&#34;&gt;\(\xi\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\eta\)&lt;/span&gt; are independent, then the joint PDF of these RVs will be the product of individual PDFs, that is &lt;span class=&#34;math inline&#34;&gt;\(f_{(\eta,\xi)}(x,y)=f_{\xi}(x)f_{\eta}(y).\)&lt;/span&gt; Therefore,&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[F_\zeta(z)=P(\eta-\xi&amp;lt;z)=\int_0^{+\infty}\int_0^{+\infty}I_{\{y-x\leq z\}}(x,y)\lambda\mu e^{-\lambda x-\mu y}d x dy.\]&lt;/span&gt;
Making the following variable change &lt;span class=&#34;math inline&#34;&gt;\(u=y-x\)&lt;/span&gt; will give
&lt;span class=&#34;math display&#34;&gt;\[F_\zeta(z)=P(\eta-\xi&amp;lt;z)=\lambda\mu \int_0^{+\infty}e^{-(\lambda + \mu) x}\left(\int_{-x}^{z}e^{-\mu u}d u\right) dx=1-\frac{\lambda}{\lambda+\mu}e^{-\mu z},\ \ z&amp;gt;0.\]&lt;/span&gt;
If &lt;span class=&#34;math inline&#34;&gt;\(z&amp;lt;0\)&lt;/span&gt; then
&lt;span class=&#34;math display&#34;&gt;\[P(\eta-\xi&amp;lt;z)=P(\xi-\eta&amp;gt;-z)=1-P(\xi-\eta&amp;lt;-z)=1-\left(1-\frac{\mu}{\mu+\lambda}e^{\lambda z}\right)=\frac{\mu}{\lambda+\mu}e^{\lambda z},\ \ z&amp;lt;0.\]&lt;/span&gt;
Therefore,
&lt;span class=&#34;math display&#34;&gt;\[F_\zeta(z)=\left\{\begin{matrix}
&amp;amp;1-\frac{\lambda}{\lambda+\mu} e^{-\mu z}, &amp;amp;z\geq 0,\\
&amp;amp;\frac{\mu}{\lambda+\mu} e^{\lambda z} &amp;amp;z&amp;lt;0.
\end{matrix}\right.\]&lt;/span&gt;
The PDF will be
&lt;span class=&#34;math display&#34;&gt;\[f_\zeta(z)=\frac{\lambda\mu}{\lambda+\mu}\left\{\begin{matrix}
&amp;amp;e^{-\mu z}, &amp;amp;z\geq 0,\\
&amp;amp;e^{\lambda z} &amp;amp;z&amp;lt;0.
\end{matrix}\right.\]&lt;/span&gt;
This formula can be checked using simulations.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rm(list=ls())

n &amp;lt;- 20000
m &amp;lt;- 10000
lambda &amp;lt;- 2
mu &amp;lt;- 5


  X &amp;lt;- rexp(n,lambda)
  Y &amp;lt;- rexp(m, mu)
  Z &amp;lt;- Y-X
  
int &amp;lt;- seq(min(Z),max(Z),(max(Z)-min(Z))/100)
dens &amp;lt;- function(z) (lambda*mu)/(lambda+mu)*ifelse(z&amp;gt;=0,exp(-mu*z),exp(lambda*z))
hist(Z, nclass = 100, freq=FALSE,ylim=c(0,1.5),
     xlim = c(min(Z),max(Z)), main=&amp;quot;&amp;quot;, col = &amp;quot;lightblue&amp;quot;, border = &amp;quot;blue&amp;quot;)
lines(int,dens(int), col=&amp;quot;2&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://gasparyan.co/post/exp/2019-12-20-r-rmarkdown_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;From the PDF we can calculate also
&lt;span class=&#34;math display&#34;&gt;\[E(\zeta)=\frac{\lambda-\mu}{\lambda\mu},\ \ P(\eta&amp;gt;\xi)=\frac{\lambda}{\lambda+\mu}.\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;example-2&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Example 2&lt;/h2&gt;
&lt;p&gt;Suppose that &lt;span class=&#34;math inline&#34;&gt;\(\eta\sim{\mathbb E}(\mu)\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\eta&amp;#39;\sim{\mathbb E}(\mu&amp;#39;)\)&lt;/span&gt; are independent. Find the distribution of the RVs &lt;span class=&#34;math inline&#34;&gt;\(\min(\eta,\eta&amp;#39;)\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\max(\eta,\eta&amp;#39;).\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;For all &lt;span class=&#34;math inline&#34;&gt;\(z&amp;gt;0\)&lt;/span&gt; we have
&lt;span class=&#34;math display&#34;&gt;\[\begin{align*}
P(\min(\eta,\eta&amp;#39;)&amp;lt;z)=1-P(\min(\eta,\eta&amp;#39;)\geq z)=1-P(\eta\geq z,\eta&amp;#39;\geq z)=1-e^{-(\mu+\mu&amp;#39;) z},\,z&amp;gt;0,
\end{align*}\]&lt;/span&gt;
and &lt;span class=&#34;math inline&#34;&gt;\(P(\min(\eta,\eta&amp;#39;)&amp;lt;z)=0,\ \ z\leq 0.\)&lt;/span&gt; Therefore, &lt;span class=&#34;math inline&#34;&gt;\(\min(\eta,\eta&amp;#39;)\sim{\mathbb E}(\mu+\mu&amp;#39;)\)&lt;/span&gt;, that is, the minimum of two exponentially distributed RVs is an exponentially distributed RV as well, with the rate being equal to the sum of the rates of the given two RVs.&lt;/p&gt;
&lt;p&gt;On the other hand,
&lt;span class=&#34;math display&#34;&gt;\[P(\max(\eta, \eta&amp;#39;) &amp;lt; z)= P(\eta &amp;lt; z, \eta&amp;#39; &amp;lt;z)=(1-e^{-\mu z})(1-e^{-\mu&amp;#39; z}),\,z&amp;gt;0.\]&lt;/span&gt;
For &lt;span class=&#34;math inline&#34;&gt;\(\mu=\mu&amp;#39;\)&lt;/span&gt; we have&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[P(\max(\eta, \eta&amp;#39;) &amp;lt; z) = (1-e^{-\mu z})^2,\,z&amp;gt;0,\]&lt;/span&gt;
with PDF being equal to &lt;span class=&#34;math inline&#34;&gt;\(f(z)=2\mu(1-e^{-\mu z})e^{-\mu z},\,z&amp;gt;0\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(f(z)=0,\,z&amp;lt;0.\)&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;example-3&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Example 3&lt;/h2&gt;
&lt;p&gt;For given three independent RVs such that &lt;span class=&#34;math inline&#34;&gt;\(\xi\sim{\mathbb E}(\lambda)\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\eta,\eta&amp;#39;\sim{\mathbb E}(\mu),\)&lt;/span&gt; calculate the following probability
&lt;span class=&#34;math inline&#34;&gt;\(\theta=P(\xi&amp;lt;\eta,\xi&amp;lt;\eta&amp;#39;).\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;We can reformulate this problem as follows
&lt;span class=&#34;math display&#34;&gt;\[\theta=P(\xi&amp;lt;\eta,\xi&amp;lt;\eta&amp;#39;)=P(\xi&amp;lt;\min(\eta,\eta&amp;#39;))=P(\xi-\min(\eta,\eta&amp;#39;)&amp;lt;0).\]&lt;/span&gt;
Hence, denoting by &lt;span class=&#34;math inline&#34;&gt;\(\zeta=\xi-\min(\eta,\eta&amp;#39;),\)&lt;/span&gt; in the first step we can calculate the distribution function of the RV &lt;span class=&#34;math inline&#34;&gt;\(\zeta.\)&lt;/span&gt; We have &lt;span class=&#34;math inline&#34;&gt;\(\xi\sim{\mathbb E}(\xi)\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\min(\eta,\eta&amp;#39;)\sim{\mathbb E}(2\mu)\)&lt;/span&gt; (see Example 2), hence, using the Example 1 we obtain&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[F_\zeta(z)=\left\{\begin{matrix}
&amp;amp;1-\frac{2\mu}{\lambda+2\mu} e^{-\lambda z}, &amp;amp;z\geq 0,\\
&amp;amp;\frac{\lambda}{\lambda+2\mu} e^{2\mu z} &amp;amp;z&amp;lt;0.
\end{matrix}\right.\]&lt;/span&gt;
For the PDF we have
&lt;span class=&#34;math display&#34;&gt;\[f_\zeta(z)=\left\{\begin{matrix}
&amp;amp;\frac{2\lambda\mu}{\lambda+2\mu} e^{-\lambda z}, &amp;amp;z&amp;gt; 0,\\
&amp;amp;\frac{2\lambda\mu}{\lambda+2\mu} e^{2\mu z} &amp;amp;z&amp;lt;0.
\end{matrix}\right.\]&lt;/span&gt;
We can, again, check this using simulations.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rm(list=ls())

n &amp;lt;- 200000
m &amp;lt;- 100000
lambda &amp;lt;- 2.5
mu &amp;lt;- 1.3


X1 &amp;lt;- rexp(n,mu)
X2 &amp;lt;- rexp(n,mu)
Y &amp;lt;- rexp(m, lambda)
Z &amp;lt;- Y - ifelse(X1&amp;gt;=X2,X2,X1)
Coeff &amp;lt;- 2*lambda*mu/(lambda+2*mu)

int &amp;lt;- seq(min(Z), max(Z), (max(Z)-min(Z))/100)
dens &amp;lt;- function(z) Coeff*ifelse(z&amp;gt;=0, exp(-lambda*z), exp(2*mu*z))


hist(Z, nclass = 100, freq=FALSE, ylim=c(0,1.5), 
     xlim=c(min(Z), max(Z)), main = &amp;quot;&amp;quot;, border = &amp;quot;blue&amp;quot;, col = &amp;quot;lightblue&amp;quot;)
lines(int,dens(int), col=&amp;quot;2&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://gasparyan.co/post/exp/2019-12-20-r-rmarkdown_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Therefore,
&lt;span class=&#34;math display&#34;&gt;\[\theta=F_\zeta(0)=\frac{\lambda}{\lambda+2\mu}.\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;example-4&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Example 4&lt;/h2&gt;
&lt;p&gt;For given three independent RVs such that &lt;span class=&#34;math inline&#34;&gt;\(\xi,\xi&amp;#39;\sim{\mathbb E}(\lambda)\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\eta\sim{\mathbb E}(\mu),\)&lt;/span&gt; calculate the following probability
&lt;span class=&#34;math inline&#34;&gt;\(\vartheta=P(\xi&amp;lt;\eta,\xi&amp;#39;&amp;lt;\eta).\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;We can reformulate this problem as follows
&lt;span class=&#34;math display&#34;&gt;\[\vartheta=P(\xi&amp;lt;\eta,\xi&amp;#39;&amp;lt;\eta)=P(\max(\xi,\xi&amp;#39;)&amp;lt;\eta)=P(\eta-\max(\xi,\xi&amp;#39;)&amp;gt;0).\]&lt;/span&gt;
Hence, denoting by &lt;span class=&#34;math inline&#34;&gt;\(\kappa=\eta-\max(\xi,\xi&amp;#39;),\)&lt;/span&gt; in the first step we can calculate the distribution function of the RV &lt;span class=&#34;math inline&#34;&gt;\(\kappa.\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{align*}
P(\kappa&amp;lt;z)=\int_0^{+\infty}\int_0^{+\infty}I(y-x\leq z)2\lambda\mu(1-e^{-\lambda x})e^{-\lambda x-\mu y}d x d y.
\end{align*}\]&lt;/span&gt;
If &lt;span class=&#34;math inline&#34;&gt;\(z&amp;gt;0\)&lt;/span&gt; then, denoting &lt;span class=&#34;math inline&#34;&gt;\(y-x=u\)&lt;/span&gt; we get &lt;span class=&#34;math inline&#34;&gt;\(y=u+x,\,u\in[-x,\infty)\ \ d y= d u.\)&lt;/span&gt; Therefore,&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{align*}
P(\kappa&amp;lt;z)&amp;amp;=2\lambda\mu\int_0^{+\infty}(1-e^{-\lambda x})e^{-\lambda x-\mu x}\int_{-x}^{z}e^{-\mu u}d u d x=\\
&amp;amp;=-2\lambda\int_0^{+\infty}(e^{-(\lambda+\mu) x -\mu z}-e^{-(2\lambda+\mu) x -\mu z}-e^{-\lambda x }+e^{-2\lambda x }) d x=\\
&amp;amp;=1-\frac{2\lambda^2}{(\lambda+\mu)(2\lambda+\mu)}e^{-\mu z },\ \ z&amp;gt;0.
\end{align*}\]&lt;/span&gt;
For &lt;span class=&#34;math inline&#34;&gt;\(z&amp;gt;0\)&lt;/span&gt; calculate also (using the notation &lt;span class=&#34;math inline&#34;&gt;\(x-y=u\)&lt;/span&gt;, which entails &lt;span class=&#34;math inline&#34;&gt;\(x=y+u,\,d x=d u,\)&lt;/span&gt; where &lt;span class=&#34;math inline&#34;&gt;\(u\in[-y,+\infty).\)&lt;/span&gt;)
&lt;span class=&#34;math display&#34;&gt;\[\begin{align*}
P(\max(\xi,\xi&amp;#39;)-\eta&amp;lt;z)&amp;amp;=\int_0^{+\infty}\int_0^{+\infty}I(x-y\leq z)2\lambda\mu(1-e^{-\lambda x})e^{-\lambda x-\mu y}d x d y=\\
&amp;amp;=\int_0^{+\infty}\int_{-y}^{z}(e^{-\lambda(y+u)  - \mu y} - e^{-2\lambda(y+u)  -\mu y}d u dy)=\\
&amp;amp;=1+\mu\left[\frac{e^{-2\lambda z}}{2\lambda+\mu}-\frac{2e^{-\lambda z}}{\lambda+\mu}\right],\ \ z\geq 0.
\end{align*}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Therefore, for &lt;span class=&#34;math inline&#34;&gt;\(z&amp;gt;0\)&lt;/span&gt; we have
&lt;span class=&#34;math display&#34;&gt;\[\begin{align*}
P(\kappa&amp;lt;-z)&amp;amp;=1-P(\max(\xi,\xi&amp;#39;)-\eta&amp;lt;z)=\\
&amp;amp;=-\mu\left[\frac{e^{-2\lambda z}}{2\lambda+\mu}-\frac{2e^{-\lambda z}}{\lambda+\mu}\right],\ \ z\geq 0
\end{align*}\]&lt;/span&gt;
Finally we obtain
&lt;span class=&#34;math display&#34;&gt;\[F_\kappa(z)=\left\{\begin{matrix}
&amp;amp;1-\frac{2\lambda^2}{(\lambda+\mu)(2\lambda+\mu)} e^{-\mu z}, &amp;amp;z\geq 0,\\
&amp;amp;-\mu\left[\frac{e^{2\lambda z}}{2\lambda+\mu}-\frac{2e^{\lambda z}}{\lambda+\mu}\right] &amp;amp;z&amp;lt;0.
\end{matrix}\right.\]&lt;/span&gt;
For the PDF we have
&lt;span class=&#34;math display&#34;&gt;\[f_\kappa(z)=\left\{\begin{matrix}
&amp;amp;\frac{2\lambda^2\mu}{(\lambda+\mu)(2\lambda+\mu)} e^{-\mu z}, &amp;amp;z&amp;gt; 0,\\
&amp;amp;-2\lambda\mu\left[\frac{e^{2\lambda z}}{2\lambda+\mu}-\frac{e^{\lambda z}}{\lambda+\mu}\right] &amp;amp;z&amp;lt;0.
\end{matrix}\right.\]&lt;/span&gt;
To check this formula we can make the following simulations.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rm(list=ls())

n &amp;lt;- 200000
m &amp;lt;- 100000
lambda &amp;lt;- 2.5
mu &amp;lt;- 5.5


X1 &amp;lt;- rexp(n,lambda)
X2 &amp;lt;- rexp(n,lambda)
Y &amp;lt;- rexp(m, mu)
Z &amp;lt;- Y - ifelse(X1 &amp;gt;= X2, X1, X2)
Coeff &amp;lt;- 2*mu*lambda^2/((lambda+mu)*(2*lambda+mu))
Coeff1 &amp;lt;- -2*lambda*mu/(2*lambda+mu)
Coeff2 &amp;lt;- -2*lambda*mu/(lambda+mu)

int &amp;lt;- seq(min(Z), max(Z), (max(Z)-min(Z))/100)

dens &amp;lt;- function(z) ifelse(z&amp;gt;=0, Coeff*exp(-mu*z),
                           Coeff1*exp(2*lambda*z)-Coeff2*exp(lambda*z))



hist(Z, nclass = 100, freq=FALSE,ylim=c(0, 1.5), xlim=c(min(Z), max(Z)),
     main = &amp;quot;&amp;quot;, col = &amp;quot;lightblue&amp;quot;, border = &amp;quot;blue&amp;quot;)
lines(int,dens(int), col=&amp;quot;2&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://gasparyan.co/post/exp/2019-12-20-r-rmarkdown_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Therefore,
&lt;span class=&#34;math display&#34;&gt;\[\vartheta=P(\xi&amp;lt;\eta, \xi&amp;#39;&amp;lt;\eta)=P(\kappa&amp;gt;0)=\frac{2\lambda^2}{(\lambda+\mu)(2\lambda+\mu)}.\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
